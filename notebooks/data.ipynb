{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778ea1c7-fa28-4232-92b6-faf51b7279a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/someshs/transuasion\n",
      "File ‘wordlist-20210729.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "%cd ~/transuasion\n",
    "!wget -nc https://github.com/wordnik/wordlist/raw/main/wordlist-20210729.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1047c3-d06f-462c-9a7f-f297d9c560d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = set(open('wordlist-20210729.txt').read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e3320d-bd74-494e-85f2-926f66c24b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.read_parquet('data/parallel_tweet_it0.parquet')\n",
    "usernames = json.load(open('data/approved_usernames.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab009a4-2a6b-47c4-9a6d-7d9716f66b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = df_pairs[(df_pairs['character_difference']>5) & (df_pairs['date_diff']<=45) & (df_pairs['similarity']>=0.5) & (df_pairs['media_x']=='') & (df_pairs['media_y']=='') & (df_pairs['username'].isin(usernames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3b06db-8021-4df0-be9f-86237db845e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = df_pairs['url'].drop_duplicates()\n",
    "rurl = url.apply(lambda x: urlparse(x[x.find('next=')+5:]) if 'next=' in x else urlparse(x))\n",
    "url_df = pd.DataFrame({'url':rurl, 'rurl':url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c9d4c3-342d-4305-afe4-14303d9f2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['netloc'] = url_df['url'].apply(lambda x: x.netloc)\n",
    "url_df['path'] = url_df['url'].apply(lambda x: x.path)\n",
    "url_df['query'] = url_df['url'].apply(lambda x: x.query)\n",
    "url_df['fragment'] = url_df['url'].apply(lambda x: x.fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbb3f09-8a9f-4085-8e16-c3ad47a3bd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netloc\n",
       "bit.ly                     57454\n",
       "www.youtube.com            15124\n",
       "buff.ly                     9741\n",
       "twitter.com                 7842\n",
       "www.liverpoolecho.co.uk     4870\n",
       "freebeacon.com              3938\n",
       "americanindependent.com     3901\n",
       "ibm.co                      3250\n",
       "www.facebook.com            2687\n",
       "totalfratmove.com           1996\n",
       "news.harvard.edu            1941\n",
       "netflixlife.com             1852\n",
       "www.totalrl.com             1640\n",
       "on.fb.me                    1531\n",
       "t.co                        1442\n",
       "www.instagram.com           1363\n",
       "houseandhome.com            1295\n",
       "tsm.social                  1243\n",
       "brook.gs                    1196\n",
       "totalsororitymove.com       1132\n",
       "cards.twitter.com           1112\n",
       "uni.cf                      1095\n",
       "on.natgeo.com               1085\n",
       "mhpbooks.com                1040\n",
       "po.st                       1018\n",
       "soundcloud.com               939\n",
       "today.ttu.edu                910\n",
       "metro.co.uk                  814\n",
       "sie.ag                       790\n",
       "dailyorange.com              785\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df['netloc'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26d57dc-c693-48c5-aa21-03dc52d70c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_url_to_tags(url):\n",
    "    # Extract words from the URL using regular expressions\n",
    "    words = re.findall(r'[A-Za-z0-9]+', url)\n",
    "\n",
    "    # Process each word based on the specified conditions\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Break camel case\n",
    "        words_split = re.findall(r'[a-z0-9]+|[A-Z][a-z0-9]*', word)\n",
    "        processed_words.extend(words_split)\n",
    "\n",
    "    # Filter words based on conditions\n",
    "    filtered_words = [word for word in processed_words if (word.isalpha() and len(word)>1) or (word.isdigit() and int(word) <= 2025)]\n",
    "\n",
    "    # Join the filtered words to create the desired string format\n",
    "    result_string = ' '.join(filtered_words)\n",
    "\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb3d233-6b19-4de1-b7bd-bdd6e0e939ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61462                                                        \n",
       "61685        The webpage can be described by keywords: 'De...\n",
       "61698        The webpage can be described by keywords: 'De...\n",
       "61705        The webpage can be described by keywords: 'De...\n",
       "61728        The webpage can be described by keywords: 'De...\n",
       "                                  ...                        \n",
       "43740089     Its domain is onekingslane  The webpage can b...\n",
       "43740095     Its domain is saveur  The webpage can be desc...\n",
       "43740159                              Its domain is seamless \n",
       "43742825     Its domain is washingtonian  The webpage can ...\n",
       "43742829     Its domain is youtube  The webpage can be des...\n",
       "Name: verb, Length: 241037, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df[\"verb\"] = url_df['path'].apply(convert_url_to_tags)\n",
    "x = ' '.join(url_df[\"verb\"]).lower().split()\n",
    "remove_tags = {k for k,v in Counter(x).items() if v<3 and k} - en\n",
    "\n",
    "def convert_url_to_tags(url):\n",
    "    # Extract words from the URL using regular expressions\n",
    "    words = re.findall(r'[A-Za-z0-9]+', url)\n",
    "\n",
    "    # Process each word based on the specified conditions\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Break camel case\n",
    "        words_split = re.findall(r'[a-z0-9]+|[A-Z][a-z0-9]*', word)\n",
    "        processed_words.extend(words_split)\n",
    "\n",
    "    # Filter words based on conditions\n",
    "    filtered_words = [word for word in processed_words if (word.isalpha() and len(word)>1 and (not (word in remove_tags))) or (word.isdigit() and int(word) <= 2025)]\n",
    "\n",
    "    # Join the filtered words to create the desired string format\n",
    "    result_string = \"', '\".join(filtered_words)\n",
    "    if len(result_string)>0:\n",
    "        return \" The webpage can be described by keywords: '\" + result_string + \"' .\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def get_domain(d):\n",
    "    d = [_d for _d in d.split('.') if not _d in [\"www\", \"com\"]]\n",
    "    if 'ly' in d or \"bitly\" in d:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return \" Its domain is \" + '.'.join(d) + ' '\n",
    "    \n",
    "domain_verb = url_df['netloc'].apply(get_domain)\n",
    "url_df['path'] = url_df['path'].apply(lambda x: '' if len(x)==7 else x)\n",
    "url_df['verb'] = domain_verb + url_df['path'].apply(convert_url_to_tags)\n",
    "url_df['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002ccb54-b920-4004-bbd2-452c81711659",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['verb'] = url_df['verb'].apply(lambda x: \"The tweet has a webpage linked to it. \" +x if len(x)>10 else x)\n",
    "url_df['url'] = url_df['url'].astype(str)\n",
    "url_verb = url_df.set_index('rurl')[\"verb\"].to_dict()\n",
    "json.dump(url_verb, open('url_verb.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935fb7de-25a8-470a-b18c-9c23284ab62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    masked_tweet = re.sub(r'@(\\w+)', '<USERNAME>', tweet)\n",
    "    usernames = re.findall(r'(@\\w+)', tweet)\n",
    "    links = re.findall(r'https?://\\S+|www\\.\\S+', tweet)\n",
    "    masked_tweet = re.sub(r'https?://\\S+|www\\.\\S+', '<HYPERLINK>', masked_tweet)\n",
    "\n",
    "    return {\n",
    "        'cleaned_tweet': masked_tweet,\n",
    "        'usernames': ' '.join(usernames),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09acfcd0-4cb2-40b8-8206-7d72bdb0a78d",
   "metadata": {},
   "source": [
    "# Pair Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8cd2a64-51cc-4718-bbc5-1f308af664dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"{} wrote a tweet.\n",
    "{} Compare the engagement levels of two tweets: Tweet (A) and Tweet (B).\n",
    "Determine which tweet will get a higher number of likes, answer (A) or (B).\n",
    "Provide the ratio of likes for (A) and (B)\n",
    "\"\"\"\n",
    "\n",
    "INSTRUCTION = \"\"\"Tweet (A) with masked mentions {}:\n",
    "'''{}'''\n",
    "\n",
    "Tweet (B) with masked mentions {}:\n",
    "'''{}'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ANSWER = \"\"\"{} will be liked {} times more\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb4e4c31-fa84-4546-ae92-c97e14414f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_0 = df_pairs[(df_pairs['likes_x'] * df_pairs['likes_y']) == 0]\n",
    "pairs_n0 = df_pairs[(df_pairs['likes_x'] * df_pairs['likes_y']) != 0]\n",
    "\n",
    "pairs_00 = pairs_0[pairs_0['likes_x'] + pairs_0['likes_y']==0] #both zero\n",
    "#pairs_0n0 = pairs_0[pairs_0['likes_x'] + pairs_0['likes_y']>0] #single zero\n",
    "\n",
    "pairs_nen = pairs_n0[pairs_n0['likes_x'] == pairs_n0['likes_y']] #non zero equals\n",
    "pairs_nnen = pairs_n0[pairs_n0['likes_x'] != pairs_n0['likes_y']] #non zero unequals\n",
    "\n",
    "pairs_nnen_close = pairs_nnen[(pairs_nnen['likes_x']+pairs_nnen['likes_y']<10) & (pairs_nnen['likes_ratio']<2)] #unequal non zero-close small values\n",
    "pairs_nnen_remain = pairs_nnen[~((pairs_nnen['likes_x']+pairs_nnen['likes_y']<10) & (pairs_nnen['likes_ratio']<2))] #unequal non zero large/far values\n",
    "\n",
    "pairs_nen_close = pairs_nen[(pairs_nen['likes_x']+pairs_nen['likes_y']<10)] #equal non zero small values\n",
    "pairs_nen_remain = pairs_nen[~((pairs_nen['likes_x']+pairs_nen['likes_y']<10))] #equal non zero large values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4491e45b-fbdd-4a57-b369-b0c918c8740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-a2e61a1d4ba8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nen_remain['tag']=\"High Non-Zero Equal Pairs\"\n",
      "<ipython-input-14-a2e61a1d4ba8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nen_close['tag']=\"Low Non-Zero Equal Pairs\"\n",
      "<ipython-input-14-a2e61a1d4ba8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nnen_close['tag']=\"Low Non-Zero Un-Equal Pairs\"\n",
      "<ipython-input-14-a2e61a1d4ba8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nnen_remain['tag']=\"High Non-Zero Un-Equal Pairs\"\n",
      "<ipython-input-14-a2e61a1d4ba8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_00['tag']=\"Zero Pairs\"\n"
     ]
    }
   ],
   "source": [
    "pairs_nen_remain['tag']=\"High Non-Zero Equal Pairs\"\n",
    "pairs_nen_close['tag']=\"Low Non-Zero Equal Pairs\"\n",
    "pairs_nnen_close['tag']=\"Low Non-Zero Un-Equal Pairs\"\n",
    "pairs_nnen_remain['tag']=\"High Non-Zero Un-Equal Pairs\"\n",
    "pairs_00['tag']=\"Zero Pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b264695-f11a-420a-9ea2-9ae502545fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Zero Pairs                      623666\n",
       "High Non-Zero Un-Equal Pairs    521620\n",
       "Low Non-Zero Un-Equal Pairs     224153\n",
       "Low Non-Zero Equal Pairs        173191\n",
       "High Non-Zero Equal Pairs        17622\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pairs_nen_remain, pairs_nen_close, pairs_nnen_close, pairs_nnen_remain, pairs_00])['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a0fb7e-cd90-4fad-85b8-bf817a4ba403",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sim = pd.concat([\n",
    "    pairs_nen_remain,\n",
    "    pairs_nnen_remain,\n",
    "    pairs_nen_close.sample(frac=0.3),\n",
    "    pairs_nnen_close.sample(frac=0.3),\n",
    "    pairs_00.sample(frac=0.1)\n",
    "]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bcafb6-07df-4d60-a979-bd3b0d05e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = (pair_sim['likes_x']+0.11) / (pair_sim['likes_y']+0.11).values\n",
    "r2 = (pair_sim['likes_y']+0.11) / (pair_sim['likes_x']+0.11).values\n",
    "pair_sim['likes_ratio'] = np.max(np.array([r1,r2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72834499-7921-4c9e-bd47-c6e6ad00e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sim['masked_tweet_x'] = pair_sim['tweet_x'].apply(clean_tweet)\n",
    "pair_sim['masked_tweet_y'] = pair_sim['tweet_y'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92c89db-733b-4e52-873b-27e5d6dbf2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36075014    (A) will be liked 1.65 times more\n",
       "5653614     (A) will be liked 1.96 times more\n",
       "36068512     (B) will be liked 1.0 times more\n",
       "23380710     (B) will be liked 2.8 times more\n",
       "28295114    (A) will be liked 1.73 times more\n",
       "                          ...                \n",
       "23480521     (A) will be liked 2.8 times more\n",
       "15787714    (B) will be liked 1.78 times more\n",
       "38225996    (A) will be liked 1.24 times more\n",
       "35914260     (B) will be liked 1.0 times more\n",
       "4030265     (A) will be liked 1.29 times more\n",
       "Length: 720812, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_sim.apply(lambda x: ANSWER.format('(A)' if x.likes_x > x.likes_y else '(B)', np.round(x.likes_ratio, 2)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5fbbe51-9cec-4a2f-b305-769b15cbe954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-1d8c63339f3a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rpair_sim['instruction'] = pair_sim.apply(lambda x: PREFIX.format(x.username, url_verb.get(x.url, '')) + '\\n' + INSTRUCTION.format(x.masked_tweet_x['usernames'], x.masked_tweet_x['cleaned_tweet'], x.masked_tweet_y['usernames'], x.masked_tweet_y['cleaned_tweet']), axis=1)\n",
      "<ipython-input-20-1d8c63339f3a>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rpair_sim['answer'] = pair_sim.apply(lambda x: ANSWER.format('(A)' if x.likes_x > x.likes_y else '(B)', np.round(x.likes_ratio, 2)),axis=1)\n"
     ]
    }
   ],
   "source": [
    "rpair_sim = pair_sim[['id_x', 'id_y', 'url', 'likes_ratio']]\n",
    "rpair_sim['instruction'] = pair_sim.apply(lambda x: PREFIX.format(x.username, url_verb.get(x.url, '')) + '\\n' + INSTRUCTION.format(x.masked_tweet_x['usernames'], x.masked_tweet_x['cleaned_tweet'], x.masked_tweet_y['usernames'], x.masked_tweet_y['cleaned_tweet']), axis=1)\n",
    "rpair_sim['answer'] = pair_sim.apply(lambda x: ANSWER.format('(A)' if x.likes_x > x.likes_y else '(B)', np.round(x.likes_ratio, 2)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d6d72c-f93b-4099-b3da-1738715ccb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_ids = set(rpair_sim['id_x']).union(set(rpair_sim['id_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9acf16d5-f27e-4439-abda-194ea1049c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543568"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f56fdb07-3585-4c63-a344-eb82766daefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpair_sim.to_parquet('data/transuasion_it4_pair_sim.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6ea814b-d3cb-4fb4-9037-5ef0c1d38e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dryrun) upload: data/transuasion_it4_pair_sim.parquet to s3://crawldatafromgcp/somesh/KPITranslation/transuasion_it4_pair_sim.parquet\n",
      "(dryrun) upload: data/wordlist-20210729.txt to s3://crawldatafromgcp/somesh/KPITranslation/wordlist-20210729.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync ./data s3://crawldatafromgcp/somesh/KPITranslation --dryrun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c5444-5a60-4794-8c88-f8ed53431f2a",
   "metadata": {},
   "source": [
    "# Transuasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849dc2e-c45b-466f-8075-981330d7a8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee739c-e79f-44d7-b46e-33b5526ca23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec237b-821f-47ba-bddc-399980cf237c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef10c1b-f4b6-4fb3-84fa-487c9cf9669c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
