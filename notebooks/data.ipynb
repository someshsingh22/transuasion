{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778ea1c7-fa28-4232-92b6-faf51b7279a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1d2c6f-900b-4f07-b641-c1b5cb2d18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/someshs/transuasion\n"
     ]
    }
   ],
   "source": [
    "%cd ~/transuasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad466da-79f0-41b9-8fbe-3ae14207906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/wordnik/wordlist/raw/main/wordlist-20210729.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1047c3-d06f-462c-9a7f-f297d9c560d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = set(open('wordlist-20210729.txt').read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e3320d-bd74-494e-85f2-926f66c24b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'parallel_tweet_it0.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparallel_tweet_it0.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m usernames \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapproved_usernames.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:220\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilesystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    228\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py:110\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'parallel_tweet_it0.parquet'"
     ]
    }
   ],
   "source": [
    "df_pairs = pd.read_parquet('parallel_tweet_it0.parquet')\n",
    "usernames = json.load(open('approved_usernames.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8ab009a4-2a6b-47c4-9a6d-7d9716f66b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = df_pairs[(df_pairs['character_difference']>5) & (df_pairs['date_diff']<=45) & (df_pairs['similarity']>=0.5) & ((df_pairs['media_x']!='') | (df_pairs['media_y']!='')) & (df_pairs['username'].isin(usernames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6f3b06db-8021-4df0-be9f-86237db845e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = df_pairs['url'].drop_duplicates()\n",
    "rurl = url.apply(lambda x: urlparse(x[x.find('next=')+5:]) if 'next=' in x else urlparse(x))\n",
    "url_df = pd.DataFrame({'url':rurl, 'rurl':url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "30c9d4c3-342d-4305-afe4-14303d9f2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['netloc'] = url_df['url'].apply(lambda x: x.netloc)\n",
    "url_df['path'] = url_df['url'].apply(lambda x: x.path)\n",
    "url_df['query'] = url_df['url'].apply(lambda x: x.query)\n",
    "url_df['fragment'] = url_df['url'].apply(lambda x: x.fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6bbb3f09-8a9f-4085-8e16-c3ad47a3bd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netloc\n",
       "bit.ly                     57454\n",
       "www.youtube.com            15124\n",
       "buff.ly                     9741\n",
       "twitter.com                 7842\n",
       "www.liverpoolecho.co.uk     4870\n",
       "freebeacon.com              3938\n",
       "americanindependent.com     3901\n",
       "ibm.co                      3250\n",
       "www.facebook.com            2687\n",
       "totalfratmove.com           1996\n",
       "news.harvard.edu            1941\n",
       "netflixlife.com             1852\n",
       "www.totalrl.com             1640\n",
       "on.fb.me                    1531\n",
       "t.co                        1442\n",
       "www.instagram.com           1363\n",
       "houseandhome.com            1295\n",
       "tsm.social                  1243\n",
       "brook.gs                    1196\n",
       "totalsororitymove.com       1132\n",
       "cards.twitter.com           1112\n",
       "uni.cf                      1095\n",
       "on.natgeo.com               1085\n",
       "mhpbooks.com                1040\n",
       "po.st                       1018\n",
       "soundcloud.com               939\n",
       "today.ttu.edu                910\n",
       "metro.co.uk                  814\n",
       "sie.ag                       790\n",
       "dailyorange.com              785\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df['netloc'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b26d57dc-c693-48c5-aa21-03dc52d70c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_url_to_tags(url):\n",
    "    # Extract words from the URL using regular expressions\n",
    "    words = re.findall(r'[A-Za-z0-9]+', url)\n",
    "\n",
    "    # Process each word based on the specified conditions\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Break camel case\n",
    "        words_split = re.findall(r'[a-z0-9]+|[A-Z][a-z0-9]*', word)\n",
    "        processed_words.extend(words_split)\n",
    "\n",
    "    # Filter words based on conditions\n",
    "    filtered_words = [word for word in processed_words if (word.isalpha() and len(word)>1) or (word.isdigit() and int(word) <= 2025)]\n",
    "\n",
    "    # Join the filtered words to create the desired string format\n",
    "    result_string = ' '.join(filtered_words)\n",
    "\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "cfb3d233-6b19-4de1-b7bd-bdd6e0e939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df[\"verb\"] = url_df['path'].apply(convert_url_to_tags)\n",
    "x = ' '.join(url_df[\"verb\"]).lower().split()\n",
    "remove_tags = {k for k,v in Counter(x).items() if v<3 and k} - en\n",
    "\n",
    "def convert_url_to_tags(url):\n",
    "    # Extract words from the URL using regular expressions\n",
    "    words = re.findall(r'[A-Za-z0-9]+', url)\n",
    "\n",
    "    # Process each word based on the specified conditions\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Break camel case\n",
    "        words_split = re.findall(r'[a-z0-9]+|[A-Z][a-z0-9]*', word)\n",
    "        processed_words.extend(words_split)\n",
    "\n",
    "    # Filter words based on conditions\n",
    "    filtered_words = [word for word in processed_words if (word.isalpha() and len(word)>1 and (not (word in remove_tags))) or (word.isdigit() and int(word) <= 2025)]\n",
    "\n",
    "    # Join the filtered words to create the desired string format\n",
    "    result_string = \"', '\".join(filtered_words)\n",
    "    if len(result_string)>0:\n",
    "        return \" The webpage can be described by keywords: '\" + result_string + \"' .\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def get_domain(d):\n",
    "    d = [_d for _d in d.split('.') if not _d in [\"www\", \"com\"]]\n",
    "    if 'ly' in d or \"bitly\" in d:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return \" Its domain is \" + '.'.join(d) + ' '\n",
    "    \n",
    "domain_verb = url_df['netloc'].apply(get_domain)\n",
    "url_df['path'] = url_df['path'].apply(lambda x: '' if len(x)==7 else x)\n",
    "url_df['verb'] = domain_verb + url_df['path'].apply(convert_url_to_tags)\n",
    "url_df['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "002ccb54-b920-4004-bbd2-452c81711659",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['verb'] = url_df['verb'].apply(lambda x: \"The tweet has a webpage linked to it. \" +x if len(x)>10 else x)\n",
    "url_df['url'] = url_df['url'].astype(str)\n",
    "url_verb = url_df.set_index('rurl')[\"verb\"].to_dict()\n",
    "json.dump(url_verb, open('url_verb.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935fb7de-25a8-470a-b18c-9c23284ab62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    masked_tweet = re.sub(r'@(\\w+)', '<USERNAME>', tweet)\n",
    "    usernames = re.findall(r'(@\\w+)', tweet)\n",
    "    links = re.findall(r'https?://\\S+|www\\.\\S+', tweet)\n",
    "    masked_tweet = re.sub(r'https?://\\S+|www\\.\\S+', '<HYPERLINK>', masked_tweet)\n",
    "\n",
    "    return {\n",
    "        'cleaned_tweet': masked_tweet,\n",
    "        'usernames': ' '.join(usernames),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09acfcd0-4cb2-40b8-8206-7d72bdb0a78d",
   "metadata": {},
   "source": [
    "# Pair Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d8cd2a64-51cc-4718-bbc5-1f308af664dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"{} wrote a tweet.\n",
    "{} Compare the engagement levels of two tweets: Tweet (A) and Tweet (B).\n",
    "Determine which tweet will get a higher number of likes, answer (A) or (B).\n",
    "Provide the ratio of likes for (A) and (B)\n",
    "\"\"\"\n",
    "\n",
    "INSTRUCTION = \"\"\"Tweet (A) with masked mentions {}:\n",
    "'''{}'''\n",
    "\n",
    "Tweet (B) with masked mentions {}:\n",
    "'''{}'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ANSWER = \"\"\"{} will be liked {} times more\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "eb4e4c31-fa84-4546-ae92-c97e14414f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_0 = df_pairs[(df_pairs['likes_x'] * df_pairs['likes_y']) == 0]\n",
    "pairs_n0 = df_pairs[(df_pairs['likes_x'] * df_pairs['likes_y']) != 0]\n",
    "\n",
    "pairs_00 = pairs_0[pairs_0['likes_x'] + pairs_0['likes_y']==0] #both zero\n",
    "#pairs_0n0 = pairs_0[pairs_0['likes_x'] + pairs_0['likes_y']>0] #single zero\n",
    "\n",
    "pairs_nen = pairs_n0[pairs_n0['likes_x'] == pairs_n0['likes_y']] #non zero equals\n",
    "pairs_nnen = pairs_n0[pairs_n0['likes_x'] != pairs_n0['likes_y']] #non zero unequals\n",
    "\n",
    "pairs_nnen_close = pairs_nnen[(pairs_nnen['likes_x']+pairs_nnen['likes_y']<10) & (pairs_nnen['likes_ratio']<2)] #unequal non zero-close small values\n",
    "pairs_nnen_remain = pairs_nnen[~((pairs_nnen['likes_x']+pairs_nnen['likes_y']<10) & (pairs_nnen['likes_ratio']<2))] #unequal non zero large/far values\n",
    "\n",
    "pairs_nen_close = pairs_nen[(pairs_nen['likes_x']+pairs_nen['likes_y']<10)] #equal non zero small values\n",
    "pairs_nen_remain = pairs_nen[~((pairs_nen['likes_x']+pairs_nen['likes_y']<10))] #equal non zero large values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4491e45b-fbdd-4a57-b369-b0c918c8740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-271-a2e61a1d4ba8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nen_remain['tag']=\"High Non-Zero Equal Pairs\"\n",
      "<ipython-input-271-a2e61a1d4ba8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nen_close['tag']=\"Low Non-Zero Equal Pairs\"\n",
      "<ipython-input-271-a2e61a1d4ba8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nnen_close['tag']=\"Low Non-Zero Un-Equal Pairs\"\n",
      "<ipython-input-271-a2e61a1d4ba8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_nnen_remain['tag']=\"High Non-Zero Un-Equal Pairs\"\n",
      "<ipython-input-271-a2e61a1d4ba8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs_00['tag']=\"Zero Pairs\"\n"
     ]
    }
   ],
   "source": [
    "pairs_nen_remain['tag']=\"High Non-Zero Equal Pairs\"\n",
    "pairs_nen_close['tag']=\"Low Non-Zero Equal Pairs\"\n",
    "pairs_nnen_close['tag']=\"Low Non-Zero Un-Equal Pairs\"\n",
    "pairs_nnen_remain['tag']=\"High Non-Zero Un-Equal Pairs\"\n",
    "pairs_00['tag']=\"Zero Pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b264695-f11a-420a-9ea2-9ae502545fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Zero Pairs                      623666\n",
       "High Non-Zero Un-Equal Pairs    521620\n",
       "Low Non-Zero Un-Equal Pairs     224153\n",
       "Low Non-Zero Equal Pairs        173191\n",
       "High Non-Zero Equal Pairs        17622\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pairs_nen_remain, pairs_nen_close, pairs_nnen_close, pairs_nnen_remain, pairs_00])['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "55a0fb7e-cd90-4fad-85b8-bf817a4ba403",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sim = pd.concat([\n",
    "    pairs_nen_remain,\n",
    "    pairs_nnen_remain,\n",
    "    pairs_nen_close.sample(frac=0.3),\n",
    "    pairs_nnen_close.sample(frac=0.3),\n",
    "    pairs_00.sample(frac=0.1)\n",
    "]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a3bcafb6-07df-4d60-a979-bd3b0d05e6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "High Non-Zero Un-Equal Pairs    521620\n",
       "Low Non-Zero Un-Equal Pairs      67246\n",
       "Zero Pairs                       62367\n",
       "Low Non-Zero Equal Pairs         51957\n",
       "High Non-Zero Equal Pairs        17622\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = (pair_sim['likes_x']+0.11) / (pair_sim['likes_y']+0.11).values\n",
    "r2 = (pair_sim['likes_y']+0.11) / (pair_sim['likes_x']+0.11).values\n",
    "pair_sim['likes_ratio'] = np.max(np.array([r1,r2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "72834499-7921-4c9e-bd47-c6e6ad00e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sim['masked_tweet_x'] = pair_sim['tweet_x'].apply(clean_tweet)\n",
    "pair_sim['masked_tweet_y'] = pair_sim['tweet_y'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bb624843-b5de-4ba0-a737-6d9b88804461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBMWatson wrote a tweet.\n",
      "The tweet has a webpage linked to it.  Its domain is techrepublic  The webpage can be described by keywords: 'article', 'the', 'future', 'of', 'ai', '10', 'scenarios', 'ibm', 'is', 'already', 'working', 'on' . Compare the engagement levels of two tweets: Tweet (A) and Tweet (B).\n",
      "Determine which tweet will get a higher number of likes, answer (A) or (B).\n",
      "Provide the ratio of likes for (A) and (B)\n",
      "\n",
      "Tweet (A) with masked mentions @TechRepublic:\n",
      "'''10 practical scenarios with how #AI is used to assist human problem-solving: <HYPERLINK> via <USERNAME>'''\n",
      "\n",
      "Tweet (B) with masked mentions @TechRepublic:\n",
      "'''How is #AI being used to assist human problem-solving? Here are 10 practical scenarios: <HYPERLINK> via <USERNAME>'''\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(.tolist()[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e92c89db-733b-4e52-873b-27e5d6dbf2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31461922    (A) will be liked 1.14 times more\n",
       "5058370     (A) will be liked 2.93 times more\n",
       "25773527    (A) will be liked 1.29 times more\n",
       "3837334     (B) will be liked 1.88 times more\n",
       "36439930    (B) will be liked 1.49 times more\n",
       "dtype: object"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_sim.apply(lambda x: ANSWER.format('(A)' if x.likes_x > x.likes_y else '(B)', np.round(x.likes_ratio, 2)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "d5fbbe51-9cec-4a2f-b305-769b15cbe954",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpair_sim = pair_sim[['id_x', 'id_y', 'url', 'likes_ratio']]\n",
    "rpair_sim['instruction'] = pair_sim.apply(lambda x: PREFIX.format(x.username, url_verb.get(x.url, '')) + '\\n' + INSTRUCTION.format(x.masked_tweet_x['usernames'], x.masked_tweet_x['cleaned_tweet'], x.masked_tweet_y['usernames'], x.masked_tweet_y['cleaned_tweet']), axis=1)\n",
    "rpair_sim['answer'] = pair_sim.apply(lambda x: ANSWER.format('(A)' if x.likes_x > x.likes_y else '(B)', np.round(x.likes_ratio, 2)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "10d6d72c-f93b-4099-b3da-1738715ccb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_ids = set(rpair_sim['id_x']).union(set(rpair_sim['id_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "9acf16d5-f27e-4439-abda-194ea1049c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544067"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c5444-5a60-4794-8c88-f8ed53431f2a",
   "metadata": {},
   "source": [
    "# Transuasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe88bc-5a16-4692-a9de-4b431bcb1d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849dc2e-c45b-466f-8075-981330d7a8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee739c-e79f-44d7-b46e-33b5526ca23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec237b-821f-47ba-bddc-399980cf237c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef10c1b-f4b6-4fb3-84fa-487c9cf9669c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
